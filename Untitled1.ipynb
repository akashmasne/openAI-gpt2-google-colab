{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akashmasne/openAI-gpt2-google-colab/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyGg7UycXT-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxeJXSoJe9Pt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "21ca4ca4-00a7-4357-d7a6-34c0559077ae"
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Total 218 (delta 0), reused 0 (delta 0), pack-reused 218\u001b[K\n",
            "Receiving objects: 100% (218/218), 4.37 MiB | 8.28 MiB/s, done.\n",
            "Resolving deltas: 100% (117/117), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7gtVcBxfEas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"gpt-2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoI_XP9OfPj7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "66798752-1b34-4018-cbff-66299b7255f2"
      },
      "source": [
        "!pip3 install tensorflow-gpu==1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n",
            "\u001b[K     |████████████████████████████████| 377.0MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.1.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.33.6)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 39.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.17.4)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 44.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (41.6.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (0.16.0)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea3WDZp8f06M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "092b3e76-c5ce-4853-e513-14f6d093dbf3"
      },
      "source": [
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (0.2.1)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCAntiGYgGd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97165fa9-31c2-417d-bd9c-9bf8fb3374ea"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You must enter the model name as a parameter, e.g.: download_model.py 124M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElgHvAbVgdpg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0beb41d6-e054-459b-881c-5334b217ca17"
      },
      "source": [
        "!python3 download_model.py 345M"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 548kit/s]                                                      \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 52.6Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 749kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:21, 64.8Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 4.67Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 47.9Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 41.3Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgr9jlaPglmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export PYTHONIOENCODING=UTF-8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWI4vFyUgxyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('src')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLqA6Es7g1Fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import model, sample#, encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OURl1_ylg34S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "38f481ee-f6e5-49e2-d006-d85fdec85c90"
      },
      "source": [
        "!pip install regex"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\r\u001b[K     |▌                               | 10kB 18.6MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 378kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 399kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 450kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 471kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 552kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 573kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 593kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 614kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 4.8MB/s \n",
            "\u001b[?25hInstalling collected packages: regex\n",
            "Successfully installed regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIibkt15V4J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7xADUBYWUCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def interact_model(\n",
        "    model_name,\n",
        "    seed,\n",
        "    nsamples,\n",
        "    batch_size,\n",
        "    length,\n",
        "    temperature,\n",
        "    top_k,\n",
        "    models_dir\n",
        "):\n",
        "    models_dir = os.path.expanduser(os.path.expandvars(models_dir))\n",
        "    if batch_size is None:\n",
        "        batch_size = 1\n",
        "    assert nsamples % batch_size == 0\n",
        "\n",
        "    enc = encoder.get_encoder(model_name, models_dir)\n",
        "    hparams = model.default_hparams()\n",
        "    with open(os.path.join(models_dir, model_name, 'hparams.json')) as f:\n",
        "        hparams.override_from_dict(json.load(f))\n",
        "\n",
        "    if length is None:\n",
        "        length = hparams.n_ctx // 2\n",
        "    elif length > hparams.n_ctx:\n",
        "        raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n",
        "\n",
        "    with tf.Session(graph=tf.Graph()) as sess:\n",
        "        context = tf.placeholder(tf.int32, [batch_size, None])\n",
        "        np.random.seed(seed)\n",
        "        tf.set_random_seed(seed)\n",
        "        output = sample.sample_sequence(\n",
        "            hparams=hparams, length=length,\n",
        "            context=context,\n",
        "            batch_size=batch_size,\n",
        "            temperature=temperature, top_k=top_k\n",
        "        )\n",
        "\n",
        "        saver = tf.train.Saver()\n",
        "        ckpt = tf.train.latest_checkpoint(os.path.join(models_dir, model_name))\n",
        "        saver.restore(sess, ckpt)\n",
        "\n",
        "        while True:\n",
        "            raw_text = input(\"Model prompt >>> \")\n",
        "            while not raw_text:\n",
        "                print('Prompt should not be empty!')\n",
        "                raw_text = input(\"Model prompt >>> \")\n",
        "            context_tokens = enc.encode(raw_text)\n",
        "            generated = 0\n",
        "            for _ in range(nsamples // batch_size):\n",
        "                out = sess.run(output, feed_dict={\n",
        "                    context: [context_tokens for _ in range(batch_size)]\n",
        "                })[:, len(context_tokens):]\n",
        "                for i in range(batch_size):\n",
        "                    generated += 1\n",
        "                    text = enc.decode(out[i])\n",
        "                    print(\"=\" * 40 + \" SAMPLE \" + str(generated) + \" \" + \"=\" * 40)\n",
        "                    print(text)\n",
        "            print(\"=\" * 80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS6R37JhWadx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "0d8ebb0b-e45c-4e57-d1c5-9a3276c8416d"
      },
      "source": [
        "interact_model(\n",
        "    '345M',\n",
        "    None,\n",
        "    1,\n",
        "    1,\n",
        "    300,\n",
        "    1,\n",
        "    0,\n",
        "    '/content/gpt-2/models'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/gpt-2/models/345M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqdkwPF_Wf_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}